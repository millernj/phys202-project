{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#1 Layer Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will make a network that will recognize 8x8 images of numbers. This will involve a creating a function that genrates networks and a function that can train the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1797, 64)\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from IPython.html.widgets import interact\n",
    "from sklearn.datasets import load_digits\n",
    "from IPython.display import Image, display\n",
    "digits = load_digits()\n",
    "print(digits.data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPYAAAD7CAYAAABZjGkWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb8deebdc50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def show_examples(i):\n",
    "    plt.matshow(digits.images[i].reshape((8,8)), cmap='Greys_r')\n",
    "    display(digits.target[i])\n",
    "interact(show_examples, i=[1,1797-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our network will be comprised of a list of numpy arrays with each array containing the weights and bias for that layer of perceptions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"http://neuralnetworksanddeeplearning.com/images/tikz35.png\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url=\"http://neuralnetworksanddeeplearning.com/images/tikz35.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Credit to [Neural Networks and Deep Learning](http://neuralnetworksanddeeplearning.com/chap1.html) by Michael Nielsen for the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 1.39743396,  0.85152653,  0.50398052],\n",
       "        [ 0.63107563,  0.04117244,  1.09626974]]),\n",
       " array([[-0.82037976, -0.82763514,  0.03610177]]),\n",
       " array([[ 0.92033585, -1.47167482],\n",
       "        [-0.59545924,  0.20487497],\n",
       "        [-0.60442366, -0.14117042]])]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def gen_network(size):\n",
    "    weights= [np.array([[np.random.randn() for _ in range(size[n-1]+1)]\n",
    "               for _ in range(size[n])]) for n in range(len(size))[1:]]\n",
    "    return weights\n",
    "a = gen_network([2,2,1,3])\n",
    "\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is our code from the Making Perceptrons notebook that we use for our network. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sigmoid = lambda x: 1/(1 +np.exp(-x))\n",
    "\n",
    "def perceptron_sigmoid(weights, inputvect):\n",
    "    return sigmoid(np.dot(np.append(inputvect,[1]), weights))\n",
    "\n",
    "def propforward(network, inputvect):\n",
    "    outputs = []\n",
    "    for layer in network:\n",
    "        neural_input = inputvect\n",
    "        output = [perceptron_sigmoid(weights, neural_input) for weights in layer]\n",
    "        outputs.append(output)\n",
    "        inputvect = output\n",
    "    \n",
    "    outputs = np.array(outputs)\n",
    "    return [outputs[:-1], outputs[-1]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we define functions to train the network based on a set of training data. The first step is to run our training data through our network to find how much error the network currently has. Since digits.target is a list of integers, we need a function to convert those integers into 10 dimensional vectors: the same format as the output of our network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def target_convert(n):\n",
    "    assert n <= 9 and n >= 0\n",
    "    n = round(n)\n",
    "    result = np.zeros((10,))\n",
    "    result[n]=1\n",
    "    return result\n",
    "target_convert(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another important function we will need is a function that will compute the output error and multipply it with the derivative ofour sigmoid function to find our output layer's deltas. These deltas will be crucial for backpropagating our error to our hidden layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_deltas_sigmoid(outputs, targets):\n",
    "    return [output*(1-output)*(output-target) for output, target in zip(outputs, targets)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have to deltas of our output layers, we move on to getting the hidden layer's deltas. To compute this, we will take the Hadamard product of the dot product of the weight array and the deltas of the succeeding array with the derivitive of that hidden layer's output.\n",
    "\n",
    "$$\\delta_{l}=((w_{l+1})^{T}\\delta_{l+1})⊙ \\sigma'(z_{l})$$\n",
    "\n",
    "This formula backpropagates the error from each layer to the previous layer so that we can change each weight by how wrong it is.\n",
    "\n",
    "Credit to [Neural Networks and Deep Learning](http://neuralnetworksanddeeplearning.com/chap1.html) by Michael Nielsen for the formula."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def backprob(network, inputvect, targets):\n",
    "    \n",
    "    hidden_outputs, outputs = propforward(network, inputvect)\n",
    "    \n",
    "    change_in_outputs = find_deltas_sigmoid(outputs, targets)\n",
    "    \n",
    "    list_deltas = [[] for _ in range(len(network))]\n",
    "    list_deltas[-1] = change_in_outputs\n",
    "    \n",
    "    for n in range(len(network))[-1:0:-1]:\n",
    "        delta = change_in_outputs\n",
    "        change_in_hidden_outputs= [hidden_output*(1-hidden_output)*\n",
    "                               np.dot(delta, np.array([n[i] for n in network[n]]).transpose())\n",
    "                               for i, hidden_output in enumerate(hidden_outputs[n-1])]\n",
    "        list_deltas[n-1] = change_in_hidden_outputs\n",
    "        change_in_outputs = change_in_hidden_outputs\n",
    "    \n",
    "    return list_deltas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we can find the deltas for each layer in the network, we just need a function to edit our weights based off of a list of examples. For that, we use stocastic gradient descent. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def stoc_descent(network, input_list, target_list, learning_rate):\n",
    "    mega_delta = []\n",
    "    hidden_output = [propforward(network, inpt)[0] for inpt in input_list]\n",
    "    for inpt, target in zip(input_list, target_list):\n",
    "        mega_delta.append(backprob(network, inpt, target))\n",
    "    \n",
    "    inputs=[]\n",
    "    inputs.append(input_list)\n",
    "    for n in range(len(network)):\n",
    "        inputs.append(hidden_output[n])\n",
    "    assert len(inputs) == len(network) + 1\n",
    "    \n",
    "    deltas = []\n",
    "    for n in range(len(network)):\n",
    "        deltas.append([np.array(delta[n]) for delta in mega_delta])\n",
    "        \n",
    "    assert len(deltas)==len(network)\n",
    "    for n in range(len(network)):\n",
    "        edit_weights(network[n], inputs[n], deltas[n], learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To edit the weights in of network, we take the 2D array in each layer and subtract it with the 2D array that results from the average of the dot products of the deltas and the inputs of that layer for the samples in the training data. This average is multiplied by a learning rate, $η$, to give us control over how much the network will change.\n",
    "\n",
    "$$w^{l}\\rightarrow w^{l}−\\frac{η}{m}\\sum_{x} \\delta_{x,l}(a_{x,l−1})^{T}$$\n",
    "\n",
    "Credit to [Neural Networks and Deep Learning](http://neuralnetworksanddeeplearning.com/chap1.html) by Michael Nielsen for the formula."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def edit_weights(layer, input_list, deltas, learning_rate):          \n",
    "        for a, inpt in enumerate(input_list):\n",
    "            layer-=learning_rate/len(input_list)*np.dot(deltas[a].reshape(len(deltas[a]),1),\n",
    "                                                        np.append(inpt,[1]).reshape(1,len(inpt)+1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, we have everything we need to train a network. All we are missing is a network to train. Let's make one and let's call him Donnel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "inputs=64\n",
    "hidden_neurons=40\n",
    "outputs=10\n",
    "donnel = gen_network([inputs,hidden_neurons,outputs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 1.02490655, -0.12901069,  0.58234328, ...,  0.44499768,\n",
       "          1.28170867, -0.26063374],\n",
       "        [ 0.48565829,  0.72317899,  1.36450463, ..., -0.14043641,\n",
       "          0.68786327, -1.07037395],\n",
       "        [ 1.0521503 ,  0.08700662,  0.87061456, ...,  0.76965983,\n",
       "          1.69780881, -0.56195861],\n",
       "        ..., \n",
       "        [-0.4658512 , -0.2373019 ,  1.99349056, ...,  1.4841913 ,\n",
       "          0.37515595, -2.04742007],\n",
       "        [ 0.48998104, -0.75082416,  0.26690011, ...,  0.24899135,\n",
       "         -0.64227781,  0.5088414 ],\n",
       "        [-0.509486  , -1.04045489, -1.93136004, ...,  0.56618208,\n",
       "          0.28546929, -2.17280312]]),\n",
       " array([[  7.31042611e-01,   6.46428609e-01,  -5.57624777e-01,\n",
       "          -9.08544209e-01,  -2.14801981e+00,  -1.63184880e+00,\n",
       "           1.09471393e+00,  -7.05995057e-01,  -5.39514280e-01,\n",
       "           3.93334456e-01,  -6.64481778e-01,   9.81108827e-01,\n",
       "           2.41231077e-01,   7.70527735e-01,  -2.51264726e-01,\n",
       "           1.42595335e+00,  -1.63102208e+00,  -8.22872069e-01,\n",
       "          -1.82788589e+00,  -6.70262561e-01,   7.57061314e-01,\n",
       "           1.27969121e-01,   5.86119678e-01,   1.06925449e+00,\n",
       "           9.20834871e-02,  -4.53489220e-01,   5.77790485e-01,\n",
       "           4.08977295e-01,  -5.00623710e-01,  -1.04178085e+00,\n",
       "           2.21613205e+00,   1.35773258e-01,   8.38997991e-02,\n",
       "           5.39751687e-01,   4.96320095e-01,   1.40575296e-01,\n",
       "           8.06472915e-01,  -6.40391206e-02,  -1.15150206e+00,\n",
       "           7.30440742e-01,  -7.52328163e-01],\n",
       "        [ -9.31275414e-01,   7.34496431e-01,  -1.51239053e+00,\n",
       "           2.02699346e+00,  -4.97898631e-02,  -1.21395003e+00,\n",
       "          -9.40135161e-01,  -3.76906941e-02,  -7.30306114e-01,\n",
       "           7.91729744e-01,  -6.03133551e-02,   2.00875704e-01,\n",
       "           1.15440045e+00,   1.31942307e-01,  -1.86968142e-01,\n",
       "           4.18751786e-01,  -1.19369163e-01,  -2.84496319e-01,\n",
       "          -2.11480034e+00,  -1.50471723e-01,  -7.06124296e-01,\n",
       "          -1.14397417e+00,   2.83013417e-01,  -1.63793419e-01,\n",
       "          -5.75868217e-01,   6.08627309e-01,   2.00195196e-01,\n",
       "           1.23969352e+00,   6.68841001e-01,  -1.25777640e+00,\n",
       "          -1.78949705e-01,   1.54336508e+00,   4.49383529e-01,\n",
       "           5.96777146e-01,  -7.23352498e-01,   2.51632205e-01,\n",
       "          -1.47555505e-01,  -1.75274574e+00,  -2.45252244e-01,\n",
       "          -1.27960662e-01,  -5.41366426e-01],\n",
       "        [  2.83290578e-01,  -6.55082471e-01,   1.65266617e-01,\n",
       "           2.71618321e-01,   1.07475577e+00,  -2.62213733e-01,\n",
       "          -3.09060854e+00,   5.31225899e-01,  -8.78270196e-01,\n",
       "           1.77556758e-01,   5.56101623e-01,  -5.39945490e-01,\n",
       "           8.40365673e-01,   5.62573622e-01,  -9.85952883e-01,\n",
       "          -1.03036236e+00,   1.18719479e+00,   5.68602338e-01,\n",
       "           5.44029549e-01,   9.82707712e-01,   2.71049034e-01,\n",
       "          -4.11734489e-02,  -4.76427487e-01,  -2.74493420e-01,\n",
       "          -7.85750354e-01,   3.21049639e-01,  -1.43539805e+00,\n",
       "          -3.10574448e-01,  -1.21127888e+00,   8.58275433e-01,\n",
       "          -2.64223424e-01,  -1.05370633e+00,  -6.75374507e-01,\n",
       "          -1.35973204e+00,   4.23683709e-01,   8.55865851e-01,\n",
       "           1.67436754e+00,   7.63683766e-01,   6.05770321e-01,\n",
       "          -9.95528953e-01,   5.75431863e-01],\n",
       "        [ -6.09081697e-01,   1.91706692e+00,  -7.47311018e-01,\n",
       "          -5.21591821e-01,  -1.40027129e+00,  -1.19302303e-01,\n",
       "          -1.08783121e-01,  -1.36626887e+00,  -1.24274651e+00,\n",
       "           8.12933459e-01,  -6.15535196e-01,  -2.29926129e+00,\n",
       "          -2.70509524e-01,   2.60398321e+00,   1.03454595e+00,\n",
       "          -1.03250368e+00,   5.91832505e-01,   1.98507692e+00,\n",
       "           4.27959562e-01,   6.15751452e-01,  -1.60100582e-01,\n",
       "           3.00095483e-01,   5.55360605e-01,  -1.22526273e+00,\n",
       "           1.67939260e-01,  -5.62832512e-01,  -1.59994077e+00,\n",
       "           1.08382314e+00,  -1.23561916e+00,   5.75633542e-01,\n",
       "           1.39240289e+00,  -3.40829574e-01,  -9.32619939e-01,\n",
       "           1.23956778e+00,  -1.70980548e+00,  -2.05203398e+00,\n",
       "          -1.32843801e+00,   9.61595250e-01,   6.77372153e-01,\n",
       "           2.79985248e-01,  -5.26396883e-01],\n",
       "        [ -5.45895459e-01,   4.12844869e-01,   9.03687666e-02,\n",
       "           2.72243190e-01,  -1.56760960e+00,  -1.30428021e+00,\n",
       "          -4.03131063e-02,  -3.87221825e-01,   1.94683910e+00,\n",
       "          -3.63198294e-01,   6.99465226e-01,  -7.54578626e-02,\n",
       "          -8.43203220e-01,  -2.87765176e+00,   4.40250663e-03,\n",
       "          -1.07517996e+00,  -5.40412690e-01,   1.62994771e+00,\n",
       "          -8.03040642e-01,  -2.92381098e-03,   6.45183068e-01,\n",
       "          -1.31257968e-01,  -4.22796616e-01,  -7.19787742e-01,\n",
       "           1.94656653e+00,   1.00129751e+00,  -4.69869925e-02,\n",
       "          -3.69534978e-01,  -4.31971039e-01,  -4.81502363e-01,\n",
       "          -2.72915342e-01,   1.90888648e+00,   7.27927848e-01,\n",
       "          -4.97528233e-01,  -9.24453623e-01,   9.05427679e-01,\n",
       "          -1.34826220e+00,  -7.38465933e-01,   1.10998890e+00,\n",
       "           6.84716104e-01,   1.53626054e+00],\n",
       "        [ -1.72532096e+00,  -8.37408424e-01,  -1.45442195e+00,\n",
       "           9.00849280e-01,   1.55597093e+00,  -1.05600460e+00,\n",
       "          -2.28554820e+00,  -9.59771802e-01,  -4.07927767e-01,\n",
       "           5.95486936e-01,  -5.05455292e-01,   5.54615813e-01,\n",
       "           2.57049971e-01,  -7.07601669e-01,   4.86139709e-01,\n",
       "          -1.40451918e+00,  -6.78568933e-02,   2.78540796e-01,\n",
       "           2.71313161e+00,   7.22205706e-01,  -1.43015550e-02,\n",
       "           6.28823761e-01,   1.00394367e+00,  -1.01246957e+00,\n",
       "           6.06520287e-01,   3.18157896e-01,   8.32285432e-01,\n",
       "          -1.56362379e-01,   1.59730493e+00,  -7.64772131e-02,\n",
       "          -1.28976658e+00,  -4.72127806e-01,  -4.68764812e-01,\n",
       "           1.55365282e-01,  -1.24879030e-02,   1.20918098e+00,\n",
       "          -4.61842606e-01,  -6.39051974e-01,  -8.65874058e-01,\n",
       "           4.85006327e-01,  -2.19557951e+00],\n",
       "        [ -1.00845892e+00,   1.04382031e+00,  -9.21286805e-01,\n",
       "           1.22542621e-01,  -5.31975217e-01,  -3.66826076e-01,\n",
       "           7.68353140e-02,   6.14892853e-02,  -5.34262978e-01,\n",
       "          -4.55826067e-01,   6.06805228e-01,   3.51604414e-01,\n",
       "          -4.97115247e-01,   1.03327935e-01,   8.37927094e-01,\n",
       "           2.62161420e-01,  -1.20130159e-02,   1.04013547e-01,\n",
       "           2.13798936e-01,   9.25040186e-01,  -8.93356692e-01,\n",
       "           1.18373356e-01,  -3.26923166e-02,  -1.00432367e-01,\n",
       "           2.54938381e-01,  -1.03426081e-01,  -4.06622816e-01,\n",
       "          -5.40405044e-01,  -1.44626984e+00,  -5.55162373e-02,\n",
       "          -3.16480737e-01,  -1.95454298e-01,   6.59180498e-01,\n",
       "          -1.90055484e+00,   1.55596598e+00,  -1.16710900e+00,\n",
       "           5.03034229e-01,   2.22541833e-01,  -2.11391551e-01,\n",
       "          -1.97202965e+00,  -7.36354611e-01],\n",
       "        [  2.19015523e-01,   1.45072685e+00,  -3.17746757e-02,\n",
       "          -1.24786831e+00,  -3.21019366e-01,  -8.34393704e-01,\n",
       "           1.46042846e+00,   3.75233229e-01,   1.06410973e-01,\n",
       "          -6.98052282e-01,  -1.36130586e+00,  -1.10241567e+00,\n",
       "           1.05354527e+00,  -2.01299988e-01,   1.10368545e+00,\n",
       "           7.49992877e-01,  -1.02141071e+00,   1.26557400e+00,\n",
       "          -1.17403447e+00,  -1.20577734e-01,  -4.14380682e-01,\n",
       "           8.13959510e-02,  -1.19708275e+00,   6.06090941e-01,\n",
       "          -1.27587590e+00,   6.54123103e-01,   8.97384292e-01,\n",
       "           1.45918057e+00,   2.75183391e-02,   1.74632557e-01,\n",
       "           1.31917186e+00,   1.58767936e-01,   1.53083009e+00,\n",
       "          -2.95525014e-01,  -2.32577687e+00,   1.06410180e+00,\n",
       "           5.61685887e-01,  -1.85298428e-01,  -4.20573813e-01,\n",
       "          -1.34065475e+00,   8.84312224e-02],\n",
       "        [  1.17538801e+00,  -5.83448263e-01,   5.89064963e-01,\n",
       "           1.21241636e+00,  -2.38398764e+00,   1.22339094e+00,\n",
       "          -1.22476412e-01,   5.86551493e-02,  -2.74566853e-01,\n",
       "           3.80245907e-01,   3.49641555e-03,  -1.88754178e-01,\n",
       "           1.91352555e-01,  -2.94648968e-01,  -5.39405490e-01,\n",
       "           1.64645097e+00,   8.63979578e-01,   6.86440604e-01,\n",
       "          -1.62581787e-01,   1.72407163e+00,  -1.87777435e-01,\n",
       "           2.22149523e+00,   1.84184532e+00,  -1.74987723e-01,\n",
       "           7.36603375e-01,  -9.59589717e-01,  -9.71143371e-01,\n",
       "          -4.06036942e-01,   1.16124873e+00,  -1.03282736e+00,\n",
       "          -1.31573662e-01,   1.61922083e+00,  -3.53072596e-01,\n",
       "           9.35231647e-01,  -1.93974475e-01,   1.63916668e+00,\n",
       "          -9.67560516e-01,   2.46212395e-01,   1.06373671e+00,\n",
       "          -1.79014542e+00,   3.65188248e-01],\n",
       "        [  1.14345783e+00,  -1.45195184e+00,   1.85079268e-01,\n",
       "          -9.97001487e-01,   4.87545342e-01,   8.39781339e-01,\n",
       "          -4.37706449e-01,  -9.68112845e-01,  -5.31025978e-01,\n",
       "           2.26807412e+00,   7.76509776e-01,  -1.58141657e+00,\n",
       "          -7.21570334e-01,   6.43791368e-01,   5.51828447e-01,\n",
       "          -1.74966302e+00,   1.71145633e+00,   9.91637461e-01,\n",
       "          -1.38042444e+00,   9.60759507e-01,  -1.79520499e+00,\n",
       "          -9.73411471e-02,   1.14673702e-01,   5.42157242e-01,\n",
       "          -8.81314089e-01,   8.75104177e-01,   6.46747628e-01,\n",
       "          -4.60279980e-01,   9.55119860e-01,   5.56113301e-01,\n",
       "          -1.81524556e-01,  -1.32376291e-01,  -2.38456694e-01,\n",
       "           1.35777457e-01,   8.83949850e-02,  -1.30434313e+00,\n",
       "          -1.40697159e+00,   1.33124773e+00,  -2.49441698e-01,\n",
       "           1.03763501e+00,  -8.14924444e-01]])]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here's what Donnel looks like.\n",
    "donnel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So as you can see, the network \"Donnel\" is simply a list of 2D numpy arrays with one array for each layer of the network. His hidden layer's shape is 40 x 65 with each row being a perceptron with 64 weights and 1 bias. Since Donnel's output layer has 10 nuerons in it, we need to be able to convert Donnel's output to numbers and numbers (0-9) into a list of perceptron outputs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def output_reader(output):\n",
    "    assert len(output)==10\n",
    "    result=[]\n",
    "    for i, t in enumerate(output):\n",
    "        if t == max(output) and abs(t-1)<=0.5:\n",
    "            result.append(i)\n",
    "    if len(result)==1:\n",
    "        return result[0]\n",
    "    else:\n",
    "        return 0\n",
    "output_reader([0,0,0,0,0,1,0,0,0,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, lets train the network with 80% of the digits data set. To do this, we will use stocastic gradient descent on batch sized iteration of the total training data set. Essentially, we're going to change our weights 15 examples at a time until we complete 80% of the dataset. Let's run this through a couple cycles as well to get our accuracy as high as possible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##This Cell Takes 20 Minutes to Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loops, best of 1: 19min 24s per loop\n"
     ]
    }
   ],
   "source": [
    "%%timeit -r1 -n1\n",
    "training_cycles = 20\n",
    "numbers_per_cycle = 1438\n",
    "batch_size = 15\n",
    "learning_rate = 1\n",
    "train_data_index = np.linspace(0,numbers_per_cycle, numbers_per_cycle + 1)\n",
    "target_list = [target_convert(n) for n in digits.target[0:numbers_per_cycle]]\n",
    "np.random.seed(1)\n",
    "np.random.shuffle(train_data_index)\n",
    "for _ in range(training_cycles):\n",
    "    for n in train_data_index:\n",
    "        if n+batch_size <= numbers_per_cycle:\n",
    "            training_data = digits.data[int(n):int(n+batch_size)]\n",
    "            target_data = target_list[int(n):int(n+batch_size)]\n",
    "        else: \n",
    "            training_data = digits.data[int(n-batch_size):numbers_per_cycle]\n",
    "            assert len(training_data)!=0\n",
    "            target_data = target_list[int(n-batch_size):numbers_per_cycle]\n",
    "        stoc_descent(donnel, training_data, target_data, learning_rate)\n",
    "And let's check how accurate it is by testing it with the remaining 20% of the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def check_net(rnge = 1438, check_number=202):\n",
    "    guesses = []\n",
    "    targets = []\n",
    "    number_correct = 0\n",
    "    rnge = range(rnge,rnge + 359)\n",
    "    for n in rnge:\n",
    "\n",
    "        guesses.append(output_reader(propforward(donnel, digits.data[n])[-1]))\n",
    "        targets.append(digits.target[n])\n",
    "\n",
    "    for guess, target in zip(guesses, targets):\n",
    "        if guess == target:\n",
    "            number_correct+=1\n",
    "    number_total = len(rnge)\n",
    "    print(number_correct/number_total*100)\n",
    "    print(\"%d/%d\" %(number_correct, number_total))\n",
    "    print()\n",
    "    print(propforward(donnel, digits.data[check_number])[-1])\n",
    "    print()\n",
    "    print(output_reader(propforward(donnel, digits.data[check_number])[-1]))\n",
    "    show_examples(check_number)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88.85793871866295\n",
      "319/359\n",
      "\n",
      "[0.0027438659871099431, 0.0012652360662671371, 2.9440062905741379e-07, 0.00046947049851415632, 0.9980317199416624, 0.00041589337476076335, 0.0004336352463562829, 0.00057988384131780232, 0.00072004772516018746, 4.0071843214092086e-05]\n",
      "\n",
      "4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPYAAAD7CAYAAABZjGkWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n1JDFlhqy2FJDFltqyGJLDf0fPKoX62kv9QUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb8df3478d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "interact(check_net, rnge=True, check_number = [1,1796])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
